<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      RoboComp &middot; 
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/website/public/css/poole.css">
  <link rel="stylesheet" href="/website/public/css/syntax.css">
  <link rel="stylesheet" href="/website/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/websitepublic/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/websitepublic/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container">
    <div class="sidebar-about">
      <h1>
        <a href="/website">
          RoboComp
        </a>
      </h1>
      <p class="lead">A simple robotics framework.</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/website">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/website/Blog/">Blog</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/website/GSoC15/">GSoC'15</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/website/GSoC16/">GSoC'16</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/website/projects/">Projects</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/website/about/">About</a>
          
        
      
        
      
        
          
            <a class="sidebar-nav-item" href="/website/contact/">Contact</a>
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/website/install/">Install</a>
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
      <a class="sidebar-nav-item" href="http://robocomp.readthedocs.org">Tutorials</a>
      <a class="sidebar-nav-item" href="https://github.com/robocomp">GitHub project</a>
      
      <span class="sidebar-nav-item">Currently v1.0.0</span>
    </nav>

    <p>&copy; 2016. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <i><b>RoboComp</b> is an open-source Robotics framework providing the tools to create and modify software components that communicate through public interfaces. Components may require, subscribe, implement or publish interfaces in a seamless way. Building new components is done using two domain specific languages, IDSL and CDSL. With IDSL you define an interface and with CDSL you specify how the component will communicate with the world. With this information, a code generator creates C++ and/or Python sources, based on CMake, that compile and execute flawlessly. When some of these features have to be changed, the component can be easily regenerated and all the user specific code is preserved thanks to a simple inheritance mechanism.</i>


<hr>

<div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/website/2015/07/02/kripa1/">
        <i>GSoC,</i> Computer vision components and libraries management <p>#1</p>
      </a>
    </h1>

    <span class="post-date">02 Jul 2015</span>

    <p><strong>About me</strong>:Hello, I am Kripasindhu Sarkar, a new PhD student at German Research Center for Artificial Intelligence (DFKI), Kaiserslautern working in the topic of Object Detection in simple and depth images. 
I am extremely interested in the topic of object detection and computer vision; specifically in solving the problem by using theories from human cognition and perception to simulate human way of visualizing the problem. 
But for now, I am focused on getting a very good grasp at the existing engineering (mostly) techniques in the field of computer vision and object detection. 
Before joining here as a PhD student I worked as a Software Engineer at Paypal for 2 years and, prior to that I did my masters and graduation from Indian Institute of Technology Kharagpur (IIT Kharagpur).</p>

<p>##Computer vision components and libraries management</p>

<p>The project is about designing and implementing a system for object detection and recognition in 3D point clouds and 2D images, and come up with a structured library with a good and easy-to-use APIs.
There has been a good amount of research in this direction and my work was to cherry-pick important ideas and present them as usable components. I’ll now explain in details the various methods I chose to
use as a part of this project.</p>

<p>###Local feature based on 2D images
The idea is the find local features (like SIFT/SURF/ORB etc) in images of the object to be detected and the given test image. If enough matches are found between the descriptors of the to images an object is defined to be found. Important assumption is that the object to be detected must have textures. Advantage is that we get the complete 6 DOF of the object which might be useful for grasping. This comes in several flavors.</p>

<ol>
  <li>
    <p>Planner objects: If we know the object is planner, we can directly compute its tomography (pose) after the match.</p>
  </li>
  <li>
    <p>Random objects: If the object is of arbitrary shape it is quite difficult to detect an object with its pose but can be done in a tricky offline phase [1]. A 3D reconstruction is performed through bundle adjustments with the object to be detected to find the 2D - 3D correspondences. On the run time, given an input image, If enough matches are found, the object is detected with its full pose by solving PnP problem.</p>
  </li>
</ol>

<p>###Dense feature based on 2D images:
The idea is the find features over a grid or a region of an image encoding the properties of that region and use that feature in some classification algorithm to perform detection. Naturally, we need to calculate dense feature over all possible region size over the image and apply the classifier; and thus it is bit slow as well. Also object pose is not identified in this type. Few of them are:</p>

<ol>
  <li>
    <p>HOG based simple classification (well known).
Difficulty in implementation: Moderate; HOG implementation with multiscale detector is present in OpenCV; but the training has to be performed separately using 3rd party tool like libsvm/matlab etc (but is straightfwd).</p>
  </li>
  <li>
    <p>HOG based Part Based Model: This is the famous and legendary and state of art (not anymore) object detector which uses LSVM.
Difficulty in implementation: Difficult; OpenCV has the detection code, but not that good. Training LSVM is not straight fwd and we need to use the original Matlab implementation of the authors.</p>
  </li>
  <li>
    <p>Wevlet based face detector with adaboost: This is also well known face detector algorithm used widely.
Difficulty in implementation: Easy; though the concept is not that straight fwd, it is readily avilable in OpenCV.</p>
  </li>
</ol>

<p>###Detection/Recognition on Depth Images
If we can get the Point Cloud with some laser scan or Kinect, there are plenty of algorithms to detect object with its pose. Again we have local feature based and global feature based algorithms described below:</p>

<ol>
  <li>
    <p>Direct object with local and global features [4]:
Very similar to that of RGB image based algorithm with difference in the types of features. Local features have the advantage that preprocessing steps like segmentation is not required but tends to be slow. On the other hand we need to do segmentation to apply global features in the clusters. But once the segmentation (like identifying planes, etc and different clusters) of the scene is done, we can use the results subsequently. 
Difficulty in implementation: Easy; components of pipeline is available in PCL.</p>
  </li>
  <li>
    <p>Object matching using classifiers: 
Global features readily available in PCL and found it to have similar results to a current benchmark but faster (10 seconds for classification testing in the benchmark [2] which uses sliding window based classification on all scales using HOG like descriptors).</p>
  </li>
</ol>

<p>##The library - Open Detection
It was decided later to have an independent library for Object Detection instead of integrating everything to Robocomp. The result is the inception of a separate library ‘Open Detection’.
The details of the design of the library is discussed in the next blog.</p>

<hr />
<p>[1] I. Gordon and D. G. Lowe, “What and where: 3d object recognition with accurate pose,” in Toward Category-Level Object Recognition, ser. Lecture Notes in Computer Science, J. Ponce, M. Hebert, C. Schmid, and A. Zisserman, Eds., vol. 4170. Springer, 2006, pp. 67–82.
[2] MOPED: A Scalable and Low Latency Object Recognition and Pose Estimation System
[3] Object Detection with Discriminatively Trained Part Based Models
[4] Aldoma, A.; Marton, Zoltan-Csaba; Tombari, F.; Wohlkinger, W.; Potthast, C.; Zeisl, B.; Rusu, R.B.; Gedikli, S.; Vincze, M., “Tutorial: Point Cloud Library: Three-Dimensional Object Recognition and 6 DOF Pose Estimation,” Robotics &amp; Automation Magazine, IEEE , vol.19, no.3,</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/website/2015/07/02/Kripa2/">
        <i>GSoC,</i> Computer vision components and libraries management <p>#2</p>
      </a>
    </h1>

    <span class="post-date">02 Jul 2015</span>

    <p><strong>Open Detection:</strong> Following the idea that it is better to have an independent library for Object Detection than contributing directly to Robocomp, I created the new library ‘Open Detection’. It is available now in the following links</p>

<ul>
  <li>
    <p>Github link: https://github.com/krips89/opendetection</p>
  </li>
  <li>
    <p>Documentation link: http://krips89.github.io/opendetection_docs/index.html</p>
  </li>
</ul>

<p>I have tried to document/provide tutorial inside the library whenever possible. So instead of writing everything here in the blog I’ll just post links to the tutorials/documentations.</p>

<p>###Installation Instructions
* Link: https://github.com/krips89/opendetection/blob/master/doc/tutorials/content/installation_instruction.rst</p>

<p>###Library Design
The basic idea was to have a library with common and simple interface giving access to varies detection methods available here. After some thinking I came up with the design explained in the following tutorial:</p>

<ul>
  <li>https://github.com/krips89/opendetection/blob/master/doc/tutorials/content/basic_structures.rst</li>
</ul>

<p>The class diagrams providing a good reference is provided here:</p>

<ul>
  <li>http://krips89.github.io/opendetection_docs/inherits.html</li>
</ul>

<p>###Documentation 
I did not document extensively till now as building an independent library from the scratch took a long time. The other very important reason is that the design is till little vulnerable to changes.
I would wait little bit more for the design to be more concrete before I start documenting extensively.</p>

<p>##Things finished 
Within this time frame I could finish the following tasks:</p>

<ol>
  <li>
    <p>Design of the library.</p>
  </li>
  <li>
    <p>Complete CMake infrastructure for modular building of the library from scratch.</p>
  </li>
  <li>
    <p>2D feature based object detection (both Training and Detection phase) with demo.</p>
  </li>
  <li>
    <p>Global feature based object detection (both training and detection phase) with demo.</p>
  </li>
  <li>
    <p>Auto generated Documentation using Doxygen (http://krips89.github.io/opendetection_docs/index.html).</p>
  </li>
  <li>
    <p>Sphinx based tutorial section to generate nice pages for tutorials and blogs like that of PCL.</p>
  </li>
  <li>
    <p>Few other Utility classes which fits the needs and design for the library.</p>
  </li>
</ol>

<p>###Milestones and things learnt:
In the next blog I’ll add the different sources I used to design and implement the above tasks and the things I learnt in this process.</p>

<hr />
<p>Kripasandhu Sarkar</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/website/2015/06/26/nithin6/">
        Build tools
      </a>
    </h1>

    <span class="post-date">26 Jun 2015</span>

    <p>###rc_init_ws
This will initialize a Robocomp workspace in the current/specified directory.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>rc_init_ws [path]
</code></pre>
</div>

<p>###rcbuild
When invoked form workspace without any arguments if not inside source path, it will build all the non-ignored components inside the workspace,  if inside any component source directory it will build only that component. But if a component is specified it will build it.</p>

<div class="highlighter-rouge"><pre class="highlight"><code> rcbuild [-h] [-i | --doc | --installdoc] [component]
</code></pre>
</div>

<p>The <code class="highlighter-rouge">doc</code> will generate documentation, <code class="highlighter-rouge">installdoc</code> will install the docs to install path, <code class="highlighter-rouge">install</code> will build and install the components. currently you can only generate docs for one component at a time.</p>

<p>###rccomp
This dosent have much functions as of now. <code class="highlighter-rouge">rccomp list</code> will list all the components.</p>

<p>###rced
when invoked as component-name file-name. it will open the the file in the component. if multiple files with same name exists, it will give choices and will ask you to choose one. It uses the editor specified in $EDITOR by default, if not present it will use <code class="highlighter-rouge">vim</code>.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>rced [-h] component file
</code></pre>
</div>

<p>###rcrun
Using rcrun you can start, stop or force stop any component from anywhere. You can also start a component in debug mode, given you have the required <em>config file</em> in the <em>etc</em> directory. If you have specified a config file then rcrun will use it to start the component. By default rcrun will use the <code class="highlighter-rouge">config</code> config file in <code class="highlighter-rouge">etc</code> directory, if not found it will search for <code class="highlighter-rouge">generic_config</code> if not found it will use any of config files present.If the debug flag is set, it will search for a config file that ends with <em>.debug</em>.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>rcrun [-h] [-s START |-st STOP | -fst FSTOP] [-d | -cf CFILE | -c CONFIG] [-is] [component]
</code></pre>
</div>

<p>###rccd
Using this you can cd into the component directory given the component name.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>rccd component
</code></pre>
</div>

<hr />
<p>Nithin Murali</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/website/2015/06/25/rajath1/">
        <i>GSoC,</i> Till Now..., (Before Midterms)
      </a>
    </h1>

    <span class="post-date">25 Jun 2015</span>

    <p><strong>Summary:</strong> Built a website for robocomp using jekyll.</p>

<p><strong>Progress:</strong> Took the task of building a website for documenting the open source project <em>RoboComp</em> for the first 4 weeks of Google Summer of Code 2015. The website should be able to segregate the posts into categories, Make it easy for users to post content and most importantly have a proper flow among the posts so that a new users will find it easy to learn the framework.</p>

<p>Started building the website by using the <a href="https://github.com/dbtek/dbyll">dbyll theme</a>. Messed around with the code a bit and had the website up for robocomp. Website <a href="https://rajathkumar.github.io/robocomp">link</a>. After a few iterations the website was all good. While exploring on the same topic stumbled upon <a href="https://rohanchandra.github.io/project/type/">Type theme</a>. Which was a jekyll based them more clean and elegant than the first one. Ported the entire website to the type theme and currently have shifted the <a href="http://robocomp.github.io/website/">website</a> to the <a href="https://github.com/robocomp">robocomp organization on github</a>. Currently have tweaked the website based on the suggetsions recieved by the mentors.</p>

<p>Version-1 : https://github.com/robocomp/website/tree/version-1</p>

<p><strong>Future:</strong> Will implement automatic segregation of posts based on categories the user mention. Extend the features of the website and add analytics, comments for blog posts etc. Give the website its final iterations based on the suggestions recieved.</p>

<hr />
<p>Rajath Kumar M.P</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/website/2015/06/25/nithin5/">
        New build system and workspace model in Robocomp <p>#2</p>
      </a>
    </h1>

    <span class="post-date">25 Jun 2015</span>

    <p>For managing these components we would need different utilities. So i started compiling a list of different utilities keeping a reference to other frameworks. Finally i have decide on my list</p>

<ul>
  <li>rc_init_ws</li>
  <li>rcbuild</li>
  <li>rced</li>
  <li>rccd</li>
  <li>rcrun</li>
  <li>rccomp</li>
</ul>

<p>For more information about the utilities see the <a href="http://robocomp.github.io/website/2015/06/26/nithin6.html">tutorial</a> on build utilities. All the utilities are implemented using python except <code class="highlighter-rouge">rccd</code> which is implemented as a shell function, As a subprocess cant affect its parents environment. So i was thinking, as anyway we will need to source a bash script, we could move the exporting of the environment variables also into that script.</p>

<p>##Future work</p>

<p>One useful feature that needs to be implemented is auto complete for the arguments. It would be a very useful feature as we don’t need need to know the exact component name, etc. Also some work on the manifest.xml has to be done. It was planned to contain basic info on packages like name, maintainer, dependencies etc. I didn’t do it right now because i was not really sure about the component dependencies, i will need to discuss about it a bit.</p>

<hr />
<p>Nithin Murali</p>

  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/website/page4">Older</a>
  
  
    
      <a class="pagination-item newer" href="/website/page2">Newer</a>
    
  
</div>
    </div>

  </body>
</html>
