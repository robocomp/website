---
layout: post
title: <i>GSoC,</i> Symbolic planning techniques for recognizing objects domestic <p>#1</p>
---
**About Me** : Hello! My name is Mercedes Paoletti √Åvila, and I would like to introduce me a little in this first post. I'm graduate in engineering from the University of Extremadura, and currently I study the Master in computer engineering and ICT management in the same University. Over the past two years I have been working in the Robotics Laboratory of the UEx, Robolab. There I developed my end grade work, "inverse kinematics in social robots", using the robotic framework implemented by the laboratory, Robocomp, and now I'm doing my Master's Thesis, that is about robots planners and is part of the project of LJ Manso, AGM. 

And just following this course of action, this project combines the two concepts (planning and inverse kinematics) for recognizing and manipulating objects, using the framework Robocomp.

##Symbolic planning techniques for recognizing objects domestic

The main object of this project is the application of symbolic techniques to build efficient pipelines in order to improve computer vision techniques, recognition and interpretation of domestic objects, to be finally executed on a domestic robot, so that the robot is able to move around a house and identify and interact with any objects located inside. The goal is that given a high-level task (eg. "grab a mug"), we can use symbolic planning techniques to build a pipeline of visual processing.

In order to reach this goal, we need some previous concepts:

1) We need a planner to organize the sequence of commands to be executed by the robot. We will use the AGM planner [1].

2) We need a system to recognize marks or some objects. For now, we wil use the algorithm proposed by Edwin Olson, AprilTags [2]

3) We also need a system that controls the movement of the robot and corrects the calibration errors and gaps of the engines. We will use the inverse kinematics component developed in Robocomp, which will add techniques of trajectory planning and visual feedback.

All this provides a robust support that allows the robot to move freely within a given environment, such as a home, and interact with everyday objects that are in it.

You can acces to the code of these components in the Robocomp repository: https://github.com/robocomp


---------
[1] AGM documentation: http://ljmanso.com/agm/

[2] AprilTags: http://april.eecs.umich.edu/papers/details.php?name=olson2011tags